version: "1.0"
services:
  spark-master:
    image: maisa/spark-master-hadoop
    container_name: spark-master
    hostname: spark-master
    tty: true
    volumes:
      - /home/maisa/cluster-hadoop/user_data:/user_data
    ports:
      - "8088:8088" # WebUI ResourceManager
      - "8080:8080" # WebUI Spark Master
      - "9870:9870" # WebUI NameNode
      - "8888:8888" # WebUI Jupyter
      - "8042:8042" # NodeManager
      - "0.0.0.0:4040:4040" # Spark
      - "0.0.0.0:18080:18080"
      - "8000:8000"  # API para o microservi√ßo
    networks:
      spark-network:
        ipv4_address: 10.5.0.2
    environment:
      - "SPARK_LOCAL_IP=10.5.0.2"
  spark-worker-1:
    image: maisa/spark-worker-hadoop
    container_name: spark-worker-1
    hostname: spark-worker-1
    tty: true
    depends_on:
      - spark-master
    ports:
      - "8081:8081" # WebUI Spark worker
      - "6042:8042" # NodeManager
    environment:
      - "SPARK_LOCAL_IP=10.5.0.3"
    networks:
      spark-network:
        ipv4_address: 10.5.0.3
  spark-worker-2:
    image: maisa/spark-worker-hadoop
    container_name: spark-worker-2
    hostname: spark-worker-2
    tty: true
    depends_on:
      - spark-master
    ports:
      - "8082:8081" # WebUI Spark worker
      - "7042:8042" # NodeManager
    environment:
     - "SPARK_LOCAL_IP=10.5.0.4"
    networks:
      spark-network:
        ipv4_address: 10.5.0.4
  mysql:
    image: mysql:latest
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: 12345
      MYSQL_DATABASE: LABORATORIO8
    ports:
      - "3306:3306"
    volumes:
      - ./mysql-init:/docker-entrypoint-initdb.d
    networks:
      spark-network:
        ipv4_address: 10.5.0.5  
networks:
  spark-network:
    driver: bridge
    ipam:
     driver: default
     config:
       - subnet: 10.5.0.0/16
